{"CoNaLa": {"avg_candidate_rank": 7.854, "avg_best_candidate_rank": 4.8, "recall": {"@5": 0.68, "@10": 0.828, "@15": 0.882, "@20": 0.916, "@25": 0.93, "@30": 0.95, "@35": 0.958, "@40": 0.962, "@45": 0.966, "@50": 0.968}, "mrr": 0.5723200367120241, "ndcg": 0.676897123391427}, "External Knowledge": {"avg_candidate_rank": 4.918269230769231, "avg_best_candidate_rank": 3.4383561643835616, "recall": {"@5": 0.8894230769230769, "@10": 0.9326923076923077, "@15": 0.9543269230769231, "@20": 0.9639423076923077, "@25": 0.96875, "@30": 0.96875, "@35": 0.9711538461538461, "@40": 0.9759615384615384, "@45": 0.9807692307692307, "@50": 0.9807692307692307}, "mrr": 0.8202377691020284, "ndcg": 0.8610420832209175}, "Web Query": {"avg_candidate_rank": 17.581261950286805, "avg_best_candidate_rank": 9.539196940726578, "recall": {"@5": 0.6032504780114722, "@10": 0.7466539196940727, "@15": 0.8173996175908221, "@20": 0.8546845124282982, "@25": 0.8718929254302104, "@30": 0.8910133843212237, "@35": 0.904397705544933, "@40": 0.9139579349904398, "@45": 0.9196940726577438, "@50": 0.9302103250478011}, "mrr": 0.49852482811071624, "ndcg": 0.6481204663768895}}