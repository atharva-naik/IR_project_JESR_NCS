{"CoNaLa": {"avg_candidate_rank": 9.472, "avg_best_candidate_rank": 5.265753424657534, "recall": {"@5": 0.672, "@10": 0.81, "@15": 0.872, "@20": 0.902, "@25": 0.92, "@30": 0.928, "@35": 0.942, "@40": 0.96, "@45": 0.966, "@50": 0.968}, "mrr": 0.5741371551368911, "ndcg": 0.6770235573576262}, "External Knowledge": {"avg_candidate_rank": 5.478365384615385, "avg_best_candidate_rank": 3.9506849315068493, "recall": {"@5": 0.8653846153846154, "@10": 0.9158653846153846, "@15": 0.9399038461538461, "@20": 0.9519230769230769, "@25": 0.9567307692307693, "@30": 0.9615384615384616, "@35": 0.9639423076923077, "@40": 0.9663461538461539, "@45": 0.9711538461538461, "@50": 0.9711538461538461}, "mrr": 0.8059529343377257, "ndcg": 0.8491163348043348}, "Web Query": {"avg_candidate_rank": 17.565965583173995, "avg_best_candidate_rank": 9.684512428298278, "recall": {"@5": 0.6042065009560229, "@10": 0.7275334608030593, "@15": 0.7963671128107075, "@20": 0.8346080305927343, "@25": 0.864244741873805, "@30": 0.8852772466539197, "@35": 0.9034416826003824, "@40": 0.9110898661567878, "@45": 0.9177820267686424, "@50": 0.9225621414913958}, "mrr": 0.4790809194100478, "ndcg": 0.6318877965229792}}