{"CoNaLa": {"avg_candidate_rank": 7.1, "avg_best_candidate_rank": 5.523287671232877, "recall": {"@5": 0.69, "@10": 0.796, "@15": 0.868, "@20": 0.908, "@25": 0.92, "@30": 0.94, "@35": 0.946, "@40": 0.964, "@45": 0.972, "@50": 0.974}, "mrr": 0.578270729428451, "ndcg": 0.6786531993833227}, "External Knowledge": {"avg_candidate_rank": 3.576923076923077, "avg_best_candidate_rank": 2.3972602739726026, "recall": {"@5": 0.90625, "@10": 0.9399038461538461, "@15": 0.9615384615384616, "@20": 0.9663461538461539, "@25": 0.96875, "@30": 0.9759615384615384, "@35": 0.9783653846153846, "@40": 0.9783653846153846, "@45": 0.9807692307692307, "@50": 0.9855769230769231}, "mrr": 0.8374906505548357, "ndcg": 0.8752148405229104}, "Web Query": {"avg_candidate_rank": 23.652007648183556, "avg_best_candidate_rank": 11.938814531548758, "recall": {"@5": 0.5200764818355641, "@10": 0.641491395793499, "@15": 0.719885277246654, "@20": 0.7667304015296367, "@25": 0.7982791586998088, "@30": 0.8231357552581262, "@35": 0.8489483747609943, "@40": 0.8690248565965584, "@45": 0.884321223709369, "@50": 0.8957934990439771}, "mrr": 0.4272650317876661, "ndcg": 0.5917632543394263}}