{"CoNaLa": {"avg_candidate_rank": 8.268, "avg_best_candidate_rank": 4.863013698630137, "recall": {"@5": 0.696, "@10": 0.82, "@15": 0.882, "@20": 0.9, "@25": 0.914, "@30": 0.936, "@35": 0.948, "@40": 0.962, "@45": 0.964, "@50": 0.97}, "mrr": 0.5846828662507998, "ndcg": 0.685561544801854}, "External Knowledge": {"avg_candidate_rank": 6.396634615384615, "avg_best_candidate_rank": 4.758904109589041, "recall": {"@5": 0.8918269230769231, "@10": 0.9254807692307693, "@15": 0.9399038461538461, "@20": 0.9591346153846154, "@25": 0.9711538461538461, "@30": 0.9711538461538461, "@35": 0.9711538461538461, "@40": 0.9711538461538461, "@45": 0.9735576923076923, "@50": 0.9735576923076923}, "mrr": 0.8130035525853939, "ndcg": 0.855101056370393}, "Web Query": {"avg_candidate_rank": 17.432122370936902, "avg_best_candidate_rank": 9.760994263862333, "recall": {"@5": 0.6051625239005736, "@10": 0.754302103250478, "@15": 0.8059273422562141, "@20": 0.8432122370936902, "@25": 0.869980879541109, "@30": 0.8910133843212237, "@35": 0.9034416826003824, "@40": 0.9082217973231358, "@45": 0.9187380497131931, "@50": 0.9282982791586998}, "mrr": 0.48260557288261335, "ndcg": 0.6358039745356872}}