{"CoNaLa": {"avg_candidate_rank": 7.93, "avg_best_candidate_rank": 5.098630136986301, "recall": {"@5": 0.684, "@10": 0.824, "@15": 0.878, "@20": 0.896, "@25": 0.916, "@30": 0.934, "@35": 0.956, "@40": 0.96, "@45": 0.968, "@50": 0.97}, "mrr": 0.5744120357148581, "ndcg": 0.6779362184899103}, "External Knowledge": {"avg_candidate_rank": 4.658653846153846, "avg_best_candidate_rank": 3.2904109589041095, "recall": {"@5": 0.8990384615384616, "@10": 0.9278846153846154, "@15": 0.9519230769230769, "@20": 0.9663461538461539, "@25": 0.96875, "@30": 0.96875, "@35": 0.96875, "@40": 0.9759615384615384, "@45": 0.9783653846153846, "@50": 0.9783653846153846}, "mrr": 0.8283106006060816, "ndcg": 0.8674013421522182}, "Web Query": {"avg_candidate_rank": 15.876673040152964, "avg_best_candidate_rank": 7.852772466539197, "recall": {"@5": 0.5917782026768642, "@10": 0.7418738049713193, "@15": 0.8107074569789675, "@20": 0.8518164435946463, "@25": 0.8747609942638623, "@30": 0.887189292543021, "@35": 0.9101338432122371, "@40": 0.9206500956022945, "@45": 0.9302103250478011, "@50": 0.9369024856596558}, "mrr": 0.4839478406163148, "ndcg": 0.6376761367454997}}