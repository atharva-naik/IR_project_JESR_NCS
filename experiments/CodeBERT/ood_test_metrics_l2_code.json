{"CoNaLa": {"avg_candidate_rank": 8.342, "avg_best_candidate_rank": 6.115068493150685, "recall": {"@5": 0.622, "@10": 0.78, "@15": 0.852, "@20": 0.88, "@25": 0.902, "@30": 0.922, "@35": 0.932, "@40": 0.95, "@45": 0.952, "@50": 0.962}, "mrr": 0.5192234969909357, "ndcg": 0.6341676434253196}, "External Knowledge": {"avg_candidate_rank": 6.735576923076923, "avg_best_candidate_rank": 6.336986301369863, "recall": {"@5": 0.7620192307692307, "@10": 0.8485576923076923, "@15": 0.8774038461538461, "@20": 0.9134615384615384, "@25": 0.9447115384615384, "@30": 0.9519230769230769, "@35": 0.9615384615384616, "@40": 0.96875, "@45": 0.9711538461538461, "@50": 0.9711538461538461}, "mrr": 0.6636340147413871, "ndcg": 0.738766825933686}}