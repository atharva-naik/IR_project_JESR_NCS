{"CoNaLa": {"avg_candidate_rank": 6.268, "avg_best_candidate_rank": 4.726027397260274, "recall": {"@5": 0.726, "@10": 0.86, "@15": 0.898, "@20": 0.922, "@25": 0.958, "@30": 0.964, "@35": 0.97, "@40": 0.97, "@45": 0.974, "@50": 0.98}, "mrr": 0.5930565228501883, "ndcg": 0.6917245105169576}, "External Knowledge": {"avg_candidate_rank": 4.581730769230769, "avg_best_candidate_rank": 2.882191780821918, "recall": {"@5": 0.9014423076923077, "@10": 0.9350961538461539, "@15": 0.9447115384615384, "@20": 0.9591346153846154, "@25": 0.9639423076923077, "@30": 0.9711538461538461, "@35": 0.9759615384615384, "@40": 0.9807692307692307, "@45": 0.9807692307692307, "@50": 0.9807692307692307}, "mrr": 0.8518556102890134, "ndcg": 0.8856851726160965}, "Web Query": {"avg_candidate_rank": 17.11185468451243, "avg_best_candidate_rank": 9.022944550669216, "recall": {"@5": 0.6147227533460803, "@10": 0.7523900573613767, "@15": 0.8260038240917782, "@20": 0.8565965583173997, "@25": 0.8776290630975143, "@30": 0.8957934990439771, "@35": 0.9082217973231358, "@40": 0.9216061185468452, "@45": 0.9330783938814532, "@50": 0.9397705544933078}, "mrr": 0.5052207549139986, "ndcg": 0.653106258747392}}