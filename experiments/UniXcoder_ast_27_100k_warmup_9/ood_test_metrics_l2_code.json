{"CoNaLa": {"avg_candidate_rank": 7.112, "avg_best_candidate_rank": 5.120547945205479, "recall": {"@5": 0.696, "@10": 0.838, "@15": 0.888, "@20": 0.916, "@25": 0.944, "@30": 0.96, "@35": 0.964, "@40": 0.97, "@45": 0.972, "@50": 0.974}, "mrr": 0.5754684670111123, "ndcg": 0.6796630339730458}, "External Knowledge": {"avg_candidate_rank": 5.158653846153846, "avg_best_candidate_rank": 3.723287671232877, "recall": {"@5": 0.8990384615384616, "@10": 0.9399038461538461, "@15": 0.9543269230769231, "@20": 0.9615384615384616, "@25": 0.96875, "@30": 0.9759615384615384, "@35": 0.9783653846153846, "@40": 0.9807692307692307, "@45": 0.9831730769230769, "@50": 0.9831730769230769}, "mrr": 0.839874532868167, "ndcg": 0.8764563719451292}, "Web Query": {"avg_candidate_rank": 17.351816443594647, "avg_best_candidate_rank": 9.097514340344167, "recall": {"@5": 0.6061185468451242, "@10": 0.751434034416826, "@15": 0.8078393881453155, "@20": 0.8460803059273423, "@25": 0.8747609942638623, "@30": 0.8919694072657743, "@35": 0.9063097514340345, "@40": 0.9130019120458891, "@45": 0.9235181644359465, "@50": 0.9302103250478011}, "mrr": 0.49074011654329036, "ndcg": 0.6426381300037766}}