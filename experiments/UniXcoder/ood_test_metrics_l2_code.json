{"CoNaLa": {"avg_candidate_rank": 6.786, "avg_best_candidate_rank": 5.605479452054794, "recall": {"@5": 0.692, "@10": 0.83, "@15": 0.882, "@20": 0.914, "@25": 0.936, "@30": 0.944, "@35": 0.958, "@40": 0.964, "@45": 0.97, "@50": 0.98}, "mrr": 0.5976652680235754, "ndcg": 0.6945352693771839}, "External Knowledge": {"avg_candidate_rank": 3.485576923076923, "avg_best_candidate_rank": 2.758904109589041, "recall": {"@5": 0.8966346153846154, "@10": 0.9375, "@15": 0.9543269230769231, "@20": 0.9615384615384616, "@25": 0.9663461538461539, "@30": 0.96875, "@35": 0.9807692307692307, "@40": 0.9855769230769231, "@45": 0.9879807692307693, "@50": 0.9903846153846154}, "mrr": 0.8236114825783875, "ndcg": 0.864703047400235}}