{"CoNaLa": {"avg_candidate_rank": 10.022, "avg_best_candidate_rank": 5.298630136986302, "recall": {"@5": 0.684, "@10": 0.832, "@15": 0.88, "@20": 0.906, "@25": 0.92, "@30": 0.938, "@35": 0.946, "@40": 0.95, "@45": 0.954, "@50": 0.958}, "mrr": 0.5757338612614159, "ndcg": 0.678184446491783}, "External Knowledge": {"avg_candidate_rank": 4.319711538461538, "avg_best_candidate_rank": 2.8493150684931505, "recall": {"@5": 0.8918269230769231, "@10": 0.9254807692307693, "@15": 0.9519230769230769, "@20": 0.9639423076923077, "@25": 0.96875, "@30": 0.96875, "@35": 0.9759615384615384, "@40": 0.9759615384615384, "@45": 0.9759615384615384, "@50": 0.9831730769230769}, "mrr": 0.8021163242835133, "ndcg": 0.8468673601044473}, "Web Query": {"avg_candidate_rank": 17.891969407265773, "avg_best_candidate_rank": 8.810707456978967, "recall": {"@5": 0.5764818355640535, "@10": 0.7256214149139579, "@15": 0.7973231357552581, "@20": 0.8365200764818356, "@25": 0.8661567877629063, "@30": 0.890057361376673, "@35": 0.9005736137667304, "@40": 0.9053537284894837, "@45": 0.9120458891013384, "@50": 0.9196940726577438}, "mrr": 0.4728012427473737, "ndcg": 0.629905364802126}}