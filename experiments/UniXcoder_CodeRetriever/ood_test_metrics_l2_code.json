{"CoNaLa": {"avg_candidate_rank": 4.574, "avg_best_candidate_rank": 3.2739726027397262, "recall": {"@5": 0.756, "@10": 0.888, "@15": 0.928, "@20": 0.952, "@25": 0.958, "@30": 0.966, "@35": 0.976, "@40": 0.98, "@45": 0.984, "@50": 0.99}, "mrr": 0.6435242595305646, "ndcg": 0.7321288065112083}, "External Knowledge": {"avg_candidate_rank": 3.3966346153846154, "avg_best_candidate_rank": 2.271232876712329, "recall": {"@5": 0.9134615384615384, "@10": 0.9302884615384616, "@15": 0.9447115384615384, "@20": 0.9519230769230769, "@25": 0.9591346153846154, "@30": 0.9639423076923077, "@35": 0.9663461538461539, "@40": 0.96875, "@45": 0.96875, "@50": 0.9783653846153846}, "mrr": 0.8543652878937116, "ndcg": 0.8884920245043837}, "Web Query": {"avg_candidate_rank": 17.233269598470365, "avg_best_candidate_rank": 8.558317399617591, "recall": {"@5": 0.5850860420650096, "@10": 0.7256214149139579, "@15": 0.7934990439770554, "@20": 0.8346080305927343, "@25": 0.8604206500956023, "@30": 0.8833652007648184, "@35": 0.9024856596558317, "@40": 0.9091778202676865, "@45": 0.9168260038240917, "@50": 0.9235181644359465}, "mrr": 0.4851888150166492, "ndcg": 0.6361595876177094}}