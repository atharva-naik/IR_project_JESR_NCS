{"CoNaLa": {"avg_candidate_rank": 9.86, "avg_best_candidate_rank": 5.304109589041096, "recall": {"@5": 0.688, "@10": 0.832, "@15": 0.882, "@20": 0.91, "@25": 0.932, "@30": 0.94, "@35": 0.956, "@40": 0.964, "@45": 0.97, "@50": 0.97}, "mrr": 0.5922426012053946, "ndcg": 0.6918571850244369}, "External Knowledge": {"avg_candidate_rank": 5.978365384615385, "avg_best_candidate_rank": 4.347945205479452, "recall": {"@5": 0.8798076923076923, "@10": 0.9206730769230769, "@15": 0.9423076923076923, "@20": 0.9591346153846154, "@25": 0.9639423076923077, "@30": 0.96875, "@35": 0.9711538461538461, "@40": 0.9711538461538461, "@45": 0.9735576923076923, "@50": 0.9735576923076923}, "mrr": 0.8025594269509754, "ndcg": 0.8469737089598866}, "Web Query": {"avg_candidate_rank": 17.032504780114724, "avg_best_candidate_rank": 8.55640535372849, "recall": {"@5": 0.5898661567877629, "@10": 0.734225621414914, "@15": 0.7973231357552581, "@20": 0.8432122370936902, "@25": 0.864244741873805, "@30": 0.8833652007648184, "@35": 0.9063097514340345, "@40": 0.9158699808795411, "@45": 0.9225621414913958, "@50": 0.9302103250478011}, "mrr": 0.47208078367016915, "ndcg": 0.6276264690017321}}