{"CoNaLa": {"avg_candidate_rank": 6.432, "avg_best_candidate_rank": 4.953424657534247, "recall": {"@5": 0.698, "@10": 0.834, "@15": 0.886, "@20": 0.922, "@25": 0.946, "@30": 0.954, "@35": 0.964, "@40": 0.968, "@45": 0.98, "@50": 0.984}, "mrr": 0.5860997076067183, "ndcg": 0.6867510732961535}, "External Knowledge": {"avg_candidate_rank": 4.300480769230769, "avg_best_candidate_rank": 2.8, "recall": {"@5": 0.8990384615384616, "@10": 0.9375, "@15": 0.9543269230769231, "@20": 0.9567307692307693, "@25": 0.9615384615384616, "@30": 0.9663461538461539, "@35": 0.9735576923076923, "@40": 0.9783653846153846, "@45": 0.9831730769230769, "@50": 0.9855769230769231}, "mrr": 0.8294469527521448, "ndcg": 0.8686444431608772}, "Web Query": {"avg_candidate_rank": 17.939770554493307, "avg_best_candidate_rank": 9.476099426386233, "recall": {"@5": 0.5793499043977055, "@10": 0.731357552581262, "@15": 0.8021032504780115, "@20": 0.8460803059273423, "@25": 0.8709369024856597, "@30": 0.8824091778202677, "@35": 0.8977055449330784, "@40": 0.9101338432122371, "@45": 0.9196940726577438, "@50": 0.9282982791586998}, "mrr": 0.48066103275335875, "ndcg": 0.6338850300301734}}