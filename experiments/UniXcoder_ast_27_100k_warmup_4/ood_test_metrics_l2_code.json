{"CoNaLa": {"avg_candidate_rank": 7.292, "avg_best_candidate_rank": 5.2465753424657535, "recall": {"@5": 0.702, "@10": 0.816, "@15": 0.872, "@20": 0.902, "@25": 0.932, "@30": 0.954, "@35": 0.96, "@40": 0.964, "@45": 0.97, "@50": 0.976}, "mrr": 0.5746636291606873, "ndcg": 0.6782881310973329}, "External Knowledge": {"avg_candidate_rank": 3.5336538461538463, "avg_best_candidate_rank": 2.232876712328767, "recall": {"@5": 0.9086538461538461, "@10": 0.9471153846153846, "@15": 0.96875, "@20": 0.9783653846153846, "@25": 0.9807692307692307, "@30": 0.9807692307692307, "@35": 0.9807692307692307, "@40": 0.9855769230769231, "@45": 0.9855769230769231, "@50": 0.9855769230769231}, "mrr": 0.8577410274040784, "ndcg": 0.8906969083606364}, "Web Query": {"avg_candidate_rank": 16.334608030592733, "avg_best_candidate_rank": 8.424474187380497, "recall": {"@5": 0.607074569789675, "@10": 0.7504780114722753, "@15": 0.8135755258126195, "@20": 0.8556405353728489, "@25": 0.8709369024856597, "@30": 0.890057361376673, "@35": 0.9005736137667304, "@40": 0.9101338432122371, "@45": 0.9177820267686424, "@50": 0.9263862332695985}, "mrr": 0.48237899971106, "ndcg": 0.6337466510897846}}