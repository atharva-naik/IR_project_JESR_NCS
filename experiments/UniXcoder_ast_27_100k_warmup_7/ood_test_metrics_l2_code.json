{"CoNaLa": {"avg_candidate_rank": 7.022, "avg_best_candidate_rank": 4.980821917808219, "recall": {"@5": 0.716, "@10": 0.85, "@15": 0.9, "@20": 0.932, "@25": 0.94, "@30": 0.952, "@35": 0.958, "@40": 0.968, "@45": 0.97, "@50": 0.976}, "mrr": 0.5930538911225675, "ndcg": 0.6929534465049048}, "External Knowledge": {"avg_candidate_rank": 4.730769230769231, "avg_best_candidate_rank": 3.4246575342465753, "recall": {"@5": 0.9086538461538461, "@10": 0.9471153846153846, "@15": 0.9591346153846154, "@20": 0.9663461538461539, "@25": 0.9711538461538461, "@30": 0.9735576923076923, "@35": 0.9783653846153846, "@40": 0.9783653846153846, "@45": 0.9783653846153846, "@50": 0.9783653846153846}, "mrr": 0.834025099613314, "ndcg": 0.8722917683886389}, "Web Query": {"avg_candidate_rank": 18.020076481835563, "avg_best_candidate_rank": 9.183556405353729, "recall": {"@5": 0.5908221797323135, "@10": 0.7275334608030593, "@15": 0.7963671128107075, "@20": 0.8413001912045889, "@25": 0.8661567877629063, "@30": 0.890057361376673, "@35": 0.8996175908221797, "@40": 0.9034416826003824, "@45": 0.9120458891013384, "@50": 0.9168260038240917}, "mrr": 0.48659367263240705, "ndcg": 0.6383088349272062}}