{"CoNaLa": {"avg_candidate_rank": 11.486, "avg_best_candidate_rank": 5.306849315068493, "recall": {"@5": 0.684, "@10": 0.818, "@15": 0.868, "@20": 0.9, "@25": 0.93, "@30": 0.944, "@35": 0.95, "@40": 0.962, "@45": 0.966, "@50": 0.968}, "mrr": 0.5838811557286152, "ndcg": 0.685152123410402}, "External Knowledge": {"avg_candidate_rank": 5.644230769230769, "avg_best_candidate_rank": 4.019178082191781, "recall": {"@5": 0.9014423076923077, "@10": 0.9302884615384616, "@15": 0.9495192307692307, "@20": 0.9663461538461539, "@25": 0.96875, "@30": 0.9735576923076923, "@35": 0.9735576923076923, "@40": 0.9759615384615384, "@45": 0.9759615384615384, "@50": 0.9759615384615384}, "mrr": 0.8357405302405418, "ndcg": 0.87312486767186}, "Web Query": {"avg_candidate_rank": 18.430210325047803, "avg_best_candidate_rank": 9.94263862332696, "recall": {"@5": 0.6252390057361377, "@10": 0.745697896749522, "@15": 0.8135755258126195, "@20": 0.8527724665391969, "@25": 0.8776290630975143, "@30": 0.890057361376673, "@35": 0.9015296367112811, "@40": 0.9101338432122371, "@45": 0.9206500956022945, "@50": 0.9263862332695985}, "mrr": 0.5034197830430696, "ndcg": 0.6508562075867497}}