{"CoNaLa": {"avg_candidate_rank": 9.646, "avg_best_candidate_rank": 5.016438356164383, "recall": {"@5": 0.688, "@10": 0.814, "@15": 0.874, "@20": 0.904, "@25": 0.922, "@30": 0.93, "@35": 0.948, "@40": 0.958, "@45": 0.964, "@50": 0.964}, "mrr": 0.5887841205962363, "ndcg": 0.688920470338604}, "External Knowledge": {"avg_candidate_rank": 5.153846153846154, "avg_best_candidate_rank": 3.6410958904109587, "recall": {"@5": 0.8894230769230769, "@10": 0.9206730769230769, "@15": 0.9447115384615384, "@20": 0.9567307692307693, "@25": 0.9639423076923077, "@30": 0.9639423076923077, "@35": 0.96875, "@40": 0.9735576923076923, "@45": 0.9735576923076923, "@50": 0.9735576923076923}, "mrr": 0.8032902983288642, "ndcg": 0.8471123386542644}, "Web Query": {"avg_candidate_rank": 17.988527724665392, "avg_best_candidate_rank": 9.11281070745698, "recall": {"@5": 0.5908221797323135, "@10": 0.7246653919694073, "@15": 0.8059273422562141, "@20": 0.8432122370936902, "@25": 0.8690248565965584, "@30": 0.8804971319311663, "@35": 0.8996175908221797, "@40": 0.9130019120458891, "@45": 0.9177820267686424, "@50": 0.9273422562141491}, "mrr": 0.47982735242479563, "ndcg": 0.6339199631345387}}