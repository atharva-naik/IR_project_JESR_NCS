{"CoNaLa": {"avg_candidate_rank": 49.314, "avg_best_candidate_rank": 40.652054794520545, "recall": {"@5": 0.442, "@10": 0.562, "@15": 0.618, "@20": 0.648, "@25": 0.68, "@30": 0.708, "@35": 0.724, "@40": 0.734, "@45": 0.752, "@50": 0.758}, "mrr": 0.35083374845789533, "ndcg": 0.481309403557387}, "External Knowledge": {"avg_candidate_rank": 0.8004807692307693, "avg_best_candidate_rank": 0.3424657534246575, "recall": {"@5": 0.9543269230769231, "@10": 0.9783653846153846, "@15": 0.9903846153846154, "@20": 0.9951923076923077, "@25": 0.9951923076923077, "@30": 0.9951923076923077, "@35": 0.9975961538461539, "@40": 0.9975961538461539, "@45": 0.9975961538461539, "@50": 1.0}, "mrr": 0.9379557669350701, "ndcg": 0.9534955446403227}, "Web Query": {"avg_candidate_rank": 81.75239005736138, "avg_best_candidate_rank": 36.67112810707457, "recall": {"@5": 0.248565965583174, "@10": 0.36233269598470363, "@15": 0.4235181644359465, "@20": 0.4713193116634799, "@25": 0.511472275334608, "@30": 0.5439770554493308, "@35": 0.5745697896749522, "@40": 0.5994263862332696, "@45": 0.615678776290631, "@50": 0.6328871892925431}, "mrr": 0.1879360491947537, "ndcg": 0.37782138621852795}}