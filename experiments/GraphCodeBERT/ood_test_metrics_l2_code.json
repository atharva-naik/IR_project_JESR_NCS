{"CoNaLa": {"avg_candidate_rank": 8.636, "avg_best_candidate_rank": 7.046575342465753, "recall": {"@5": 0.662, "@10": 0.792, "@15": 0.852, "@20": 0.888, "@25": 0.916, "@30": 0.936, "@35": 0.95, "@40": 0.954, "@45": 0.96, "@50": 0.962}, "mrr": 0.5703330333092476, "ndcg": 0.6730435554783328}, "External Knowledge": {"avg_candidate_rank": 6.1875, "avg_best_candidate_rank": 5.109589041095891, "recall": {"@5": 0.8076923076923077, "@10": 0.8822115384615384, "@15": 0.9038461538461539, "@20": 0.9206730769230769, "@25": 0.9375, "@30": 0.9447115384615384, "@35": 0.9495192307692307, "@40": 0.9591346153846154, "@45": 0.96875, "@50": 0.9711538461538461}, "mrr": 0.7170723208031528, "ndcg": 0.7810804034388181}}