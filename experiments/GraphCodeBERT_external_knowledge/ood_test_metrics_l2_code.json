{"CoNaLa": {"avg_candidate_rank": 25.914, "avg_best_candidate_rank": 21.46301369863014, "recall": {"@5": 0.436, "@10": 0.55, "@15": 0.618, "@20": 0.68, "@25": 0.718, "@30": 0.75, "@35": 0.782, "@40": 0.806, "@45": 0.83, "@50": 0.848}, "mrr": 0.36440526453605565, "ndcg": 0.4986605103331685}, "External Knowledge": {"avg_candidate_rank": 0.5408653846153846, "avg_best_candidate_rank": 0.15342465753424658, "recall": {"@5": 0.96875, "@10": 0.9879807692307693, "@15": 0.9927884615384616, "@20": 0.9951923076923077, "@25": 1.0, "@30": 1.0, "@35": 1.0, "@40": 1.0, "@45": 1.0, "@50": 1.0}, "mrr": 0.9585319042889336, "ndcg": 0.9698946317896748}}