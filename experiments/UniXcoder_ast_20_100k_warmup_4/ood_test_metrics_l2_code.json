{"CoNaLa": {"avg_candidate_rank": 7.31, "avg_best_candidate_rank": 5.257534246575342, "recall": {"@5": 0.702, "@10": 0.818, "@15": 0.872, "@20": 0.9, "@25": 0.934, "@30": 0.956, "@35": 0.96, "@40": 0.964, "@45": 0.97, "@50": 0.976}, "mrr": 0.5757691638438562, "ndcg": 0.6792444942650756}, "External Knowledge": {"avg_candidate_rank": 3.5384615384615383, "avg_best_candidate_rank": 2.243835616438356, "recall": {"@5": 0.9086538461538461, "@10": 0.9471153846153846, "@15": 0.96875, "@20": 0.9783653846153846, "@25": 0.9807692307692307, "@30": 0.9807692307692307, "@35": 0.9807692307692307, "@40": 0.9855769230769231, "@45": 0.9855769230769231, "@50": 0.9855769230769231}, "mrr": 0.8571153032958625, "ndcg": 0.8901802562766646}, "Web Query": {"avg_candidate_rank": 16.379541108986615, "avg_best_candidate_rank": 8.497131931166347, "recall": {"@5": 0.6061185468451242, "@10": 0.7523900573613767, "@15": 0.8145315487571702, "@20": 0.8575525812619503, "@25": 0.872848948374761, "@30": 0.8891013384321224, "@35": 0.8996175908221797, "@40": 0.9101338432122371, "@45": 0.9177820267686424, "@50": 0.9273422562141491}, "mrr": 0.48124556216965464, "ndcg": 0.6328156719998853}}