{"CoNaLa": {"avg_candidate_rank": 9.024, "avg_best_candidate_rank": 4.706849315068493, "recall": {"@5": 0.692, "@10": 0.826, "@15": 0.886, "@20": 0.92, "@25": 0.934, "@30": 0.95, "@35": 0.96, "@40": 0.966, "@45": 0.972, "@50": 0.974}, "mrr": 0.5675792038468689, "ndcg": 0.6730693474585615}, "External Knowledge": {"avg_candidate_rank": 4.173076923076923, "avg_best_candidate_rank": 3.128767123287671, "recall": {"@5": 0.8846153846153846, "@10": 0.9399038461538461, "@15": 0.9615384615384616, "@20": 0.96875, "@25": 0.9735576923076923, "@30": 0.9735576923076923, "@35": 0.9783653846153846, "@40": 0.9783653846153846, "@45": 0.9783653846153846, "@50": 0.9783653846153846}, "mrr": 0.8190742209784728, "ndcg": 0.8605770494764402}, "Web Query": {"avg_candidate_rank": 16.631931166347993, "avg_best_candidate_rank": 8.059273422562141, "recall": {"@5": 0.5812619502868069, "@10": 0.745697896749522, "@15": 0.8021032504780115, "@20": 0.8422562141491395, "@25": 0.8652007648183556, "@30": 0.8948374760994264, "@35": 0.9015296367112811, "@40": 0.9139579349904398, "@45": 0.9235181644359465, "@50": 0.9359464627151052}, "mrr": 0.4794414876078156, "ndcg": 0.6327296568034241}}