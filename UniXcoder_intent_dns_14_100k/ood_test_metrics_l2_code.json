{"CoNaLa": {"avg_candidate_rank": 8.562, "avg_best_candidate_rank": 6.046575342465753, "recall": {"@5": 0.664, "@10": 0.8, "@15": 0.844, "@20": 0.876, "@25": 0.912, "@30": 0.932, "@35": 0.944, "@40": 0.952, "@45": 0.96, "@50": 0.962}, "mrr": 0.570834055502088, "ndcg": 0.6730927822387229}, "External Knowledge": {"avg_candidate_rank": 3.206730769230769, "avg_best_candidate_rank": 2.0054794520547947, "recall": {"@5": 0.9086538461538461, "@10": 0.9375, "@15": 0.9591346153846154, "@20": 0.9711538461538461, "@25": 0.9759615384615384, "@30": 0.9831730769230769, "@35": 0.9831730769230769, "@40": 0.9855769230769231, "@45": 0.9855769230769231, "@50": 0.9855769230769231}, "mrr": 0.8579197394548418, "ndcg": 0.8905114820539195}, "Web Query": {"avg_candidate_rank": 24.904397705544934, "avg_best_candidate_rank": 11.133843212237094, "recall": {"@5": 0.5162523900573613, "@10": 0.6606118546845124, "@15": 0.7179732313575525, "@20": 0.7571701720841301, "@25": 0.7963671128107075, "@30": 0.8221797323135756, "@35": 0.8479923518164436, "@40": 0.858508604206501, "@45": 0.8747609942638623, "@50": 0.884321223709369}, "mrr": 0.4236705429641885, "ndcg": 0.5892909676177064}}