{"CoNaLa": {"avg_candidate_rank": 13.988, "avg_best_candidate_rank": 11.736986301369862, "recall": {"@5": 0.51, "@10": 0.662, "@15": 0.728, "@20": 0.78, "@25": 0.83, "@30": 0.856, "@35": 0.882, "@40": 0.908, "@45": 0.93, "@50": 0.936}, "mrr": 0.4058590514144692, "ndcg": 0.5390945295109496}, "External Knowledge": {"avg_candidate_rank": 7.189903846153846, "avg_best_candidate_rank": 5.136986301369863, "recall": {"@5": 0.7764423076923077, "@10": 0.8653846153846154, "@15": 0.8870192307692307, "@20": 0.9134615384615384, "@25": 0.9302884615384616, "@30": 0.9375, "@35": 0.9447115384615384, "@40": 0.9519230769230769, "@45": 0.9567307692307693, "@50": 0.9567307692307693}, "mrr": 0.679898709699407, "ndcg": 0.7519515504853918}, "Web Query": {"avg_candidate_rank": 34.06405353728489, "avg_best_candidate_rank": 14.617590822179732, "recall": {"@5": 0.4063097514340344, "@10": 0.5468451242829828, "@15": 0.6233269598470363, "@20": 0.6720841300191205, "@25": 0.7160611854684512, "@30": 0.7466539196940727, "@35": 0.768642447418738, "@40": 0.7934990439770554, "@45": 0.8068833652007649, "@50": 0.8221797323135756}, "mrr": 0.3360684500229969, "ndcg": 0.513301360312388}}